{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 19 - Data Science Masters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What are the three stages to build the hypotheses or model in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "The Three stages to build the hypotheses or Model in machine learning are\n",
    "1. Data Preperation - Data cleaning and genaration of Training and Test sets of data\n",
    "2. Model Building and Optimising - Training the algorithm on the train set of data. Minimizing loss function (bias-variance error) by selection or deletion or modification of features(columns), Train-Test split and modifying parameters (or hyper-parameters). This is done through various performance metrics based on type of ML algorithm(model) used. Evaluation and selection of right algorithm. \n",
    "3. Deployment  - Deploying the model and monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is the standard approach to supervised learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "The standard approach to supervised learning is to Identify predictors and target variables, clean the data set, split the dataset in consideration, into the training set and the test set. Build the model using train set data and evaluate the model using test set data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. What is Training set and Test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "Training set: The set of data that is used to discover the potentially predictive relationship between input and outputs of a model is known as ‘Training Set’.  It is a set of known inputs and outputs used to train the machine. It lets the model(algorithm) identify patterns in the data and create rules for predicting the output.\n",
    "\n",
    "Test set: The set of data that is used to check how well the model works after it is trained with the training set is known as ‘Test set’. It is used to check the accuracy of the hypotheses generated by the model as well as other performance metrics after learning from the training set data.\n",
    "\n",
    "Training set must be distinct from the Test set. Test set should a similar distribution as that of training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer \n",
    "Ensemble method is combining of two or more machine learning algorithms or models to achieve (or predict) a better result than what each model could achieve when used individually. The models can be based on different algorithms or same algorithms used again with different parameters.\n",
    "\n",
    "The general principle of an ensemble method is to combine the predictions of several models built with a given learning algorithm to improve robustness over a single model. This is achieved by bagging and boosting.\n",
    "\n",
    "Bagging is an abbreviation for \"bootstrap aggregating\". It's meta-algorithm, which takes M subsamples (with replacement) from the initial dataset and trains the predictive model on those subsamples. The final model is obtained by averaging the \"bootstrapped\" models and usually yields better results.\n",
    "\n",
    "Boosting is a method that builds weak learners into strong ensembles by focusing iterations on the error terms of the previous iteration. Boosting is used sequentially to reduce the bias of the combined model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How can you avoid overfitting ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer \n",
    "Overfitting can be avoided by using the following methods:\n",
    "\n",
    "a.\tUsing larger training data: By using a dataset containing a lot of training data, overfitting can be avoided. Overfitting happens when you have a small dataset, and you try to learn from it. \n",
    "\n",
    "b.\tCross Validation: If you have a small dataset and you are forced to come with a model based on that. In such situation, one can use cross validation to avoid overfitting.  There are different methods of cross validation:\n",
    "\n",
    "    i.\tValidation Set: The dataset is split into, testing, validation and training datasets, the testing dataset will only test the model while, in training dataset, the datapoints will come up with the model and validation set is used to optimize the model.\n",
    "\n",
    "    ii.\tK-Fold Cross validation: Validates the model by creating k-folds and training the model on k-1 folds and testing it on the kth fold and calculating the score for it. And then it repeats the same process for different folds in the training dataset. The standard deviation of the scores should be as minimal as possible.\n",
    "    \n",
    "    iii.\tStratified k-fold cross validation: Same as k-fold CV but takes into consideration the high variation and discrepancy in the training dataset to reduce overfitting.\n",
    "    \n",
    "    iv.\tAdversarial cross validation\n",
    "    \n",
    "c.\tRegularization:  Using models such as Lasso, Ridge and Elasticnet  \n",
    "\n",
    "d.\tUsing Feature Engineering and Feature Selection methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
